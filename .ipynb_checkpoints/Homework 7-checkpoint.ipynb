{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "usual-jordan",
   "metadata": {},
   "source": [
    "## Homework 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-shannon",
   "metadata": {},
   "source": [
    "#### Conceptual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-springfield",
   "metadata": {},
   "source": [
    "##### 3. We now review k-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-glucose",
   "metadata": {},
   "source": [
    "###### (a) Explain how k-fold cross-validation is implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-diagnosis",
   "metadata": {},
   "source": [
    "> the oberservation set is divided in k groups/folds with approximately the same size. The first fold is the validation/test set and the other 1-k folds are the training sets on which the method is implemented. The test error is the the mean of the k test error estimates. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-bulletin",
   "metadata": {},
   "source": [
    "###### (b) What are the advantages and disadvantages of k-fold cross- validation relative to:\n",
    "i. The validation set approach? \n",
    "> The validation set approach can only use half of the data to fit a model. Also, the validation estimate of the test error rate can be highly variable, depending on precisely which observations are included in the training set and which observations are included in the validation set.\n",
    "\n",
    "ii. LOOCV? \n",
    "> the advantage is that k-fold CV can be less computational expensive because one can choose a smaller k than k = n. K-fold CV also often gives more accurate estimates ot the test error rate. There is a bias-variance trade-off when it comes to choosing the best k. Rule of thumb is k = 5 or k = 10. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-therapist",
   "metadata": {},
   "source": [
    "#### Applied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-agreement",
   "metadata": {},
   "source": [
    "##### 7. In Sections 5.3.2 and 5.3.3, we saw that the cv.glm() function can be used in order to compute the LOOCV test error estimate. Alternatively, one could compute those quantities using just the glm() and predict.glm() functions, and a for loop. You will now take this approach in order to compute the LOOCV error for a simple logistic regression model on the Weekly data set. Recall that in the context of classification problems, the LOOCV error is given in (5.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fitted-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ISLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-converter",
   "metadata": {},
   "source": [
    "###### (a) Fit a logistic regression model that predicts Direction using Lag1 and Lag2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "thermal-details",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Direction ~ Lag1 + Lag2, family = binomial, data = Weekly)\n",
       "\n",
       "Deviance Residuals: \n",
       "   Min      1Q  Median      3Q     Max  \n",
       "-1.623  -1.261   1.001   1.083   1.506  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)  0.22122    0.06147   3.599 0.000319 ***\n",
       "Lag1        -0.03872    0.02622  -1.477 0.139672    \n",
       "Lag2         0.06025    0.02655   2.270 0.023232 *  \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 1496.2  on 1088  degrees of freedom\n",
       "Residual deviance: 1488.2  on 1086  degrees of freedom\n",
       "AIC: 1494.2\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.1 <- glm(Direction ~ Lag1 + Lag2, data = Weekly, family = binomial)\n",
    "summary(model.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-hammer",
   "metadata": {},
   "source": [
    "###### (b) Fit a logistic regression model that predicts Direction using Lag1 and Lag2 using all but the first observation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "criminal-version",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Direction ~ Lag1 + Lag2, family = binomial, data = Weekly[-1, \n",
       "    ])\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.6258  -1.2617   0.9999   1.0819   1.5071  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)  0.22324    0.06150   3.630 0.000283 ***\n",
       "Lag1        -0.03843    0.02622  -1.466 0.142683    \n",
       "Lag2         0.06085    0.02656   2.291 0.021971 *  \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 1494.6  on 1087  degrees of freedom\n",
       "Residual deviance: 1486.5  on 1085  degrees of freedom\n",
       "AIC: 1492.5\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.2 <- glm(Direction ~ Lag1 + Lag2, data = Weekly[-1,], family = binomial)\n",
    "summary(model.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-clinic",
   "metadata": {},
   "source": [
    "###### (c) Use the model from (b) to predict the direction of the first observation. You can do this by predicting that the first observation will go up if P(Direction=\"Up\"|Lag1, Lag2) > 0.5. Was this observation correctly classified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "equivalent-instruction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>1:</strong> TRUE"
      ],
      "text/latex": [
       "\\textbf{1:} TRUE"
      ],
      "text/markdown": [
       "**1:** TRUE"
      ],
      "text/plain": [
       "   1 \n",
       "TRUE "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Year</th><th scope=col>Lag1</th><th scope=col>Lag2</th><th scope=col>Lag3</th><th scope=col>Lag4</th><th scope=col>Lag5</th><th scope=col>Volume</th><th scope=col>Today</th><th scope=col>Direction</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1990</td><td> 0.816</td><td> 1.572</td><td>-3.936</td><td>-0.229</td><td>-3.484</td><td>0.1549760</td><td>-0.270</td><td>Down</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>1990</td><td>-0.270</td><td> 0.816</td><td> 1.572</td><td>-3.936</td><td>-0.229</td><td>0.1485740</td><td>-2.576</td><td>Down</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>1990</td><td>-2.576</td><td>-0.270</td><td> 0.816</td><td> 1.572</td><td>-3.936</td><td>0.1598375</td><td> 3.514</td><td>Up  </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>1990</td><td> 3.514</td><td>-2.576</td><td>-0.270</td><td> 0.816</td><td> 1.572</td><td>0.1616300</td><td> 0.712</td><td>Up  </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>1990</td><td> 0.712</td><td> 3.514</td><td>-2.576</td><td>-0.270</td><td> 0.816</td><td>0.1537280</td><td> 1.178</td><td>Up  </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>1990</td><td> 1.178</td><td> 0.712</td><td> 3.514</td><td>-2.576</td><td>-0.270</td><td>0.1544440</td><td>-1.372</td><td>Down</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 9\n",
       "\\begin{tabular}{r|lllllllll}\n",
       "  & Year & Lag1 & Lag2 & Lag3 & Lag4 & Lag5 & Volume & Today & Direction\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <fct>\\\\\n",
       "\\hline\n",
       "\t1 & 1990 &  0.816 &  1.572 & -3.936 & -0.229 & -3.484 & 0.1549760 & -0.270 & Down\\\\\n",
       "\t2 & 1990 & -0.270 &  0.816 &  1.572 & -3.936 & -0.229 & 0.1485740 & -2.576 & Down\\\\\n",
       "\t3 & 1990 & -2.576 & -0.270 &  0.816 &  1.572 & -3.936 & 0.1598375 &  3.514 & Up  \\\\\n",
       "\t4 & 1990 &  3.514 & -2.576 & -0.270 &  0.816 &  1.572 & 0.1616300 &  0.712 & Up  \\\\\n",
       "\t5 & 1990 &  0.712 &  3.514 & -2.576 & -0.270 &  0.816 & 0.1537280 &  1.178 & Up  \\\\\n",
       "\t6 & 1990 &  1.178 &  0.712 &  3.514 & -2.576 & -0.270 & 0.1544440 & -1.372 & Down\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 9\n",
       "\n",
       "| <!--/--> | Year &lt;dbl&gt; | Lag1 &lt;dbl&gt; | Lag2 &lt;dbl&gt; | Lag3 &lt;dbl&gt; | Lag4 &lt;dbl&gt; | Lag5 &lt;dbl&gt; | Volume &lt;dbl&gt; | Today &lt;dbl&gt; | Direction &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1990 |  0.816 |  1.572 | -3.936 | -0.229 | -3.484 | 0.1549760 | -0.270 | Down |\n",
       "| 2 | 1990 | -0.270 |  0.816 |  1.572 | -3.936 | -0.229 | 0.1485740 | -2.576 | Down |\n",
       "| 3 | 1990 | -2.576 | -0.270 |  0.816 |  1.572 | -3.936 | 0.1598375 |  3.514 | Up   |\n",
       "| 4 | 1990 |  3.514 | -2.576 | -0.270 |  0.816 |  1.572 | 0.1616300 |  0.712 | Up   |\n",
       "| 5 | 1990 |  0.712 |  3.514 | -2.576 | -0.270 |  0.816 | 0.1537280 |  1.178 | Up   |\n",
       "| 6 | 1990 |  1.178 |  0.712 |  3.514 | -2.576 | -0.270 | 0.1544440 | -1.372 | Down |\n",
       "\n"
      ],
      "text/plain": [
       "  Year Lag1   Lag2   Lag3   Lag4   Lag5   Volume    Today  Direction\n",
       "1 1990  0.816  1.572 -3.936 -0.229 -3.484 0.1549760 -0.270 Down     \n",
       "2 1990 -0.270  0.816  1.572 -3.936 -0.229 0.1485740 -2.576 Down     \n",
       "3 1990 -2.576 -0.270  0.816  1.572 -3.936 0.1598375  3.514 Up       \n",
       "4 1990  3.514 -2.576 -0.270  0.816  1.572 0.1616300  0.712 Up       \n",
       "5 1990  0.712  3.514 -2.576 -0.270  0.816 0.1537280  1.178 Up       \n",
       "6 1990  1.178  0.712  3.514 -2.576 -0.270 0.1544440 -1.372 Down     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict.glm(model.2, Weekly[1, ], type = \"response\") > 0.5\n",
    "head(Weekly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-staff",
   "metadata": {},
   "source": [
    "> the prediction for the direction of the first obervation is Up (> 0.5). This prediction is wrong as the true direction for the first observation is Down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-profile",
   "metadata": {},
   "source": [
    "###### (d) Write a loop from i=1 to i=n, where n is the number of observations in the data set, that performs each of the following steps:\n",
    "i. Fit a logistic regression model using all but the ith observation to predict Direction using Lag1 and Lag2.\n",
    "ii. Compute the posterior probability of the market moving up for the ith observation.\n",
    "iii. Use the posterior probability for the ith observation in order to predict whether or not the market moves up.\n",
    "iv. Determine whether or not an error was made in predicting the direction for the ith observation. If an error was made, then indicate this as a 1, and otherwise indicate it as a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "extra-breathing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1</li><li>1</li><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>0</li><li>1</li><li>1</li><li>1</li><li>1</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>0</li><li>1</li><li>1</li><li>1</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>1</li><li>1</li><li>0</li><li>0</li><li>1</li><li>0</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>1</li><li>1</li><li>0</li><li>0</li><li>1</li><li>1</li><li>0</li><li>1</li><li>1</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>1</li><li>1</li><li>0</li><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>1</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>1</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>1</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>1</li><li>1</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>1</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>1</li><li>1</li><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>1</li><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>⋯</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>0</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>1</li><li>1</li><li>1</li><li>0</li><li>0</li><li>1</li><li>1</li><li>0</li><li>1</li><li>1</li><li>1</li><li>1</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>1</li><li>1</li><li>1</li><li>0</li><li>0</li><li>1</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>1</li><li>1</li><li>0</li><li>0</li><li>1</li><li>1</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>1</li><li>1</li><li>1</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>1</li><li>0</li><li>1</li><li>1</li><li>1</li><li>0</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>1</li><li>1</li><li>1</li><li>1</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>1</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item ⋯\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 1\n",
       "3. 0\n",
       "4. 1\n",
       "5. 0\n",
       "6. 1\n",
       "7. 0\n",
       "8. 0\n",
       "9. 0\n",
       "10. 1\n",
       "11. 1\n",
       "12. 0\n",
       "13. 0\n",
       "14. 0\n",
       "15. 1\n",
       "16. 0\n",
       "17. 1\n",
       "18. 0\n",
       "19. 1\n",
       "20. 0\n",
       "21. 0\n",
       "22. 0\n",
       "23. 1\n",
       "24. 1\n",
       "25. 1\n",
       "26. 1\n",
       "27. 1\n",
       "28. 1\n",
       "29. 0\n",
       "30. 1\n",
       "31. 1\n",
       "32. 1\n",
       "33. 1\n",
       "34. 0\n",
       "35. 1\n",
       "36. 0\n",
       "37. 0\n",
       "38. 0\n",
       "39. 1\n",
       "40. 0\n",
       "41. 1\n",
       "42. 0\n",
       "43. 0\n",
       "44. 1\n",
       "45. 0\n",
       "46. 1\n",
       "47. 1\n",
       "48. 1\n",
       "49. 0\n",
       "50. 1\n",
       "51. 0\n",
       "52. 0\n",
       "53. 0\n",
       "54. 1\n",
       "55. 0\n",
       "56. 0\n",
       "57. 1\n",
       "58. 1\n",
       "59. 0\n",
       "60. 0\n",
       "61. 0\n",
       "62. 0\n",
       "63. 1\n",
       "64. 0\n",
       "65. 1\n",
       "66. 1\n",
       "67. 0\n",
       "68. 0\n",
       "69. 1\n",
       "70. 0\n",
       "71. 1\n",
       "72. 1\n",
       "73. 0\n",
       "74. 0\n",
       "75. 0\n",
       "76. 1\n",
       "77. 0\n",
       "78. 1\n",
       "79. 1\n",
       "80. 0\n",
       "81. 0\n",
       "82. 1\n",
       "83. 1\n",
       "84. 0\n",
       "85. 1\n",
       "86. 1\n",
       "87. 0\n",
       "88. 0\n",
       "89. 1\n",
       "90. 0\n",
       "91. 0\n",
       "92. 1\n",
       "93. 1\n",
       "94. 1\n",
       "95. 0\n",
       "96. 0\n",
       "97. 0\n",
       "98. 0\n",
       "99. 0\n",
       "100. 1\n",
       "101. 0\n",
       "102. 1\n",
       "103. 1\n",
       "104. 0\n",
       "105. 0\n",
       "106. 1\n",
       "107. 0\n",
       "108. 1\n",
       "109. 0\n",
       "110. 0\n",
       "111. 1\n",
       "112. 1\n",
       "113. 0\n",
       "114. 0\n",
       "115. 1\n",
       "116. 0\n",
       "117. 0\n",
       "118. 1\n",
       "119. 0\n",
       "120. 0\n",
       "121. 1\n",
       "122. 1\n",
       "123. 1\n",
       "124. 1\n",
       "125. 0\n",
       "126. 0\n",
       "127. 0\n",
       "128. 1\n",
       "129. 0\n",
       "130. 1\n",
       "131. 0\n",
       "132. 1\n",
       "133. 1\n",
       "134. 0\n",
       "135. 0\n",
       "136. 0\n",
       "137. 1\n",
       "138. 1\n",
       "139. 1\n",
       "140. 0\n",
       "141. 0\n",
       "142. 0\n",
       "143. 1\n",
       "144. 0\n",
       "145. 0\n",
       "146. 0\n",
       "147. 0\n",
       "148. 0\n",
       "149. 0\n",
       "150. 1\n",
       "151. 1\n",
       "152. 1\n",
       "153. 0\n",
       "154. 1\n",
       "155. 0\n",
       "156. 0\n",
       "157. 1\n",
       "158. 1\n",
       "159. 0\n",
       "160. 0\n",
       "161. 0\n",
       "162. 0\n",
       "163. 1\n",
       "164. 1\n",
       "165. 0\n",
       "166. 0\n",
       "167. 1\n",
       "168. 0\n",
       "169. 0\n",
       "170. 1\n",
       "171. 0\n",
       "172. 0\n",
       "173. 1\n",
       "174. 1\n",
       "175. 1\n",
       "176. 0\n",
       "177. 1\n",
       "178. 0\n",
       "179. 1\n",
       "180. 0\n",
       "181. 0\n",
       "182. 0\n",
       "183. 0\n",
       "184. 0\n",
       "185. 0\n",
       "186. 0\n",
       "187. 0\n",
       "188. 1\n",
       "189. 1\n",
       "190. 0\n",
       "191. 1\n",
       "192. 0\n",
       "193. 1\n",
       "194. 0\n",
       "195. 1\n",
       "196. 0\n",
       "197. 1\n",
       "198. 0\n",
       "199. 0\n",
       "200. 1\n",
       "201. ⋯\n",
       "202. 0\n",
       "203. 0\n",
       "204. 0\n",
       "205. 1\n",
       "206. 0\n",
       "207. 0\n",
       "208. 0\n",
       "209. 0\n",
       "210. 0\n",
       "211. 0\n",
       "212. 0\n",
       "213. 1\n",
       "214. 0\n",
       "215. 1\n",
       "216. 0\n",
       "217. 1\n",
       "218. 0\n",
       "219. 0\n",
       "220. 0\n",
       "221. 1\n",
       "222. 1\n",
       "223. 1\n",
       "224. 1\n",
       "225. 1\n",
       "226. 0\n",
       "227. 1\n",
       "228. 1\n",
       "229. 0\n",
       "230. 0\n",
       "231. 0\n",
       "232. 0\n",
       "233. 0\n",
       "234. 1\n",
       "235. 0\n",
       "236. 0\n",
       "237. 1\n",
       "238. 0\n",
       "239. 0\n",
       "240. 0\n",
       "241. 0\n",
       "242. 1\n",
       "243. 0\n",
       "244. 1\n",
       "245. 1\n",
       "246. 1\n",
       "247. 0\n",
       "248. 0\n",
       "249. 1\n",
       "250. 1\n",
       "251. 0\n",
       "252. 1\n",
       "253. 1\n",
       "254. 1\n",
       "255. 1\n",
       "256. 0\n",
       "257. 1\n",
       "258. 0\n",
       "259. 0\n",
       "260. 0\n",
       "261. 1\n",
       "262. 0\n",
       "263. 1\n",
       "264. 0\n",
       "265. 1\n",
       "266. 0\n",
       "267. 0\n",
       "268. 1\n",
       "269. 1\n",
       "270. 1\n",
       "271. 1\n",
       "272. 1\n",
       "273. 0\n",
       "274. 1\n",
       "275. 0\n",
       "276. 0\n",
       "277. 0\n",
       "278. 1\n",
       "279. 1\n",
       "280. 1\n",
       "281. 0\n",
       "282. 0\n",
       "283. 1\n",
       "284. 1\n",
       "285. 1\n",
       "286. 0\n",
       "287. 0\n",
       "288. 0\n",
       "289. 0\n",
       "290. 1\n",
       "291. 1\n",
       "292. 0\n",
       "293. 0\n",
       "294. 0\n",
       "295. 0\n",
       "296. 1\n",
       "297. 0\n",
       "298. 0\n",
       "299. 1\n",
       "300. 1\n",
       "301. 1\n",
       "302. 0\n",
       "303. 0\n",
       "304. 1\n",
       "305. 1\n",
       "306. 0\n",
       "307. 0\n",
       "308. 1\n",
       "309. 0\n",
       "310. 0\n",
       "311. 0\n",
       "312. 0\n",
       "313. 1\n",
       "314. 0\n",
       "315. 0\n",
       "316. 1\n",
       "317. 0\n",
       "318. 1\n",
       "319. 0\n",
       "320. 0\n",
       "321. 1\n",
       "322. 1\n",
       "323. 1\n",
       "324. 1\n",
       "325. 0\n",
       "326. 1\n",
       "327. 0\n",
       "328. 0\n",
       "329. 1\n",
       "330. 0\n",
       "331. 0\n",
       "332. 1\n",
       "333. 0\n",
       "334. 0\n",
       "335. 1\n",
       "336. 1\n",
       "337. 0\n",
       "338. 1\n",
       "339. 1\n",
       "340. 1\n",
       "341. 0\n",
       "342. 1\n",
       "343. 1\n",
       "344. 0\n",
       "345. 0\n",
       "346. 0\n",
       "347. 1\n",
       "348. 0\n",
       "349. 1\n",
       "350. 0\n",
       "351. 1\n",
       "352. 1\n",
       "353. 1\n",
       "354. 1\n",
       "355. 0\n",
       "356. 0\n",
       "357. 1\n",
       "358. 0\n",
       "359. 0\n",
       "360. 0\n",
       "361. 0\n",
       "362. 0\n",
       "363. 0\n",
       "364. 1\n",
       "365. 0\n",
       "366. 1\n",
       "367. 1\n",
       "368. 0\n",
       "369. 0\n",
       "370. 0\n",
       "371. 0\n",
       "372. 0\n",
       "373. 1\n",
       "374. 1\n",
       "375. 1\n",
       "376. 0\n",
       "377. 0\n",
       "378. 0\n",
       "379. 1\n",
       "380. 0\n",
       "381. 1\n",
       "382. 1\n",
       "383. 1\n",
       "384. 0\n",
       "385. 0\n",
       "386. 0\n",
       "387. 0\n",
       "388. 1\n",
       "389. 0\n",
       "390. 0\n",
       "391. 0\n",
       "392. 0\n",
       "393. 0\n",
       "394. 1\n",
       "395. 0\n",
       "396. 1\n",
       "397. 0\n",
       "398. 0\n",
       "399. 0\n",
       "400. 0\n",
       "401. 0\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   [1] 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0\n",
       "  [38] 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 1 0 0 1 0 1 1 0 0\n",
       "  [75] 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 0 1\n",
       " [112] 1 0 0 1 0 0 1 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0\n",
       " [149] 0 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0\n",
       " [186] 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 1\n",
       " [223] 0 0 0 1 1 1 0 1 0 1 0 1 0 0 0 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 0 1 0\n",
       " [260] 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0\n",
       " [297] 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0\n",
       " [334] 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1\n",
       " [371] 1 1 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0 1\n",
       " [408] 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1\n",
       " [445] 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0\n",
       " [482] 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0\n",
       " [519] 1 1 0 0 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 1 1 1 1\n",
       " [556] 1 1 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 1\n",
       " [593] 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1\n",
       " [630] 0 1 1 1 1 0 1 1 0 0 0 1 1 1 1 0 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 0 1 0 0\n",
       " [667] 0 1 1 0 1 0 1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 1\n",
       " [704] 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
       " [741] 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 1 0 0 0 1\n",
       " [778] 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 1\n",
       " [815] 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1\n",
       " [852] 1 1 0 1 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1\n",
       " [889] 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 0 0 0 0 0 1 0 0 1\n",
       " [926] 0 0 0 0 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 0 1\n",
       " [963] 0 0 0 1 1 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1 0 0 1 0 0 0\n",
       "[1000] 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0\n",
       "[1037] 1 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0\n",
       "[1074] 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loop <- rep(0, dim(Weekly)[1])\n",
    "for (i in 1:dim(Weekly) [1]) {\n",
    "    model.3 <- glm(Direction ~ Lag1 + Lag2, data = Weekly[-i,], family = binomial)\n",
    "    predict <- predict.glm(model.2, Weekly[i, ], type = \"response\") > 0.5\n",
    "    true <- Weekly[i, ]$Direction == \"Up\"\n",
    "    if (predict != true)\n",
    "        loop[i] <- 1}\n",
    "loop  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-district",
   "metadata": {},
   "source": [
    "###### (e) Take the average of the n numbers obtained in (d)iv in order to obtain the LOOCV estimate for the test error. Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cloudy-glucose",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.443526170798898"
      ],
      "text/latex": [
       "0.443526170798898"
      ],
      "text/markdown": [
       "0.443526170798898"
      ],
      "text/plain": [
       "[1] 0.4435262"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-render",
   "metadata": {},
   "source": [
    "> the LOOCV estimate for the test error is approximately 44%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-series",
   "metadata": {},
   "source": [
    "##### 9. We will now consider the Boston housing data set, from the MASS library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bigger-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-cholesterol",
   "metadata": {},
   "source": [
    "###### (a) Based on this data set, provide an estimate for the population mean of medv. Call this estimate μˆ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "numerical-aggregate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "22.5328063241107"
      ],
      "text/latex": [
       "22.5328063241107"
      ],
      "text/markdown": [
       "22.5328063241107"
      ],
      "text/plain": [
       "[1] 22.53281"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu <- mean(Boston$medv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-armenia",
   "metadata": {},
   "source": [
    "###### (b) Provide an estimate of the standard error of μˆ. Interpret this result.\n",
    "Hint: We can compute the standard error of the sample mean by dividing the sample standard deviation by the square root of the number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hairy-enzyme",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.408861147497535"
      ],
      "text/latex": [
       "0.408861147497535"
      ],
      "text/markdown": [
       "0.408861147497535"
      ],
      "text/plain": [
       "[1] 0.4088611"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "se.mu <- sd(medv)/sqrt(dim(Boston)[1])\n",
    "se.mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-vision",
   "metadata": {},
   "source": [
    "> the sd error tells us how far away the estimated mean is from the true mean. Compared to the mean, the standard error is small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-confusion",
   "metadata": {},
   "source": [
    "###### (c) Now estimate the standard error of μˆ using the bootstrap. How does this compare to your answer from (b)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "drawn-fantasy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = medv, statistic = boot.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "    original      bias    std. error\n",
       "t1* 22.53281 0.007650791   0.4106622"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(boot)\n",
    "set.seed(1)\n",
    "boot.fn <- function(data, index)return(mean(data[index])) \n",
    "boot(medv, boot.fn, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-voluntary",
   "metadata": {},
   "source": [
    "> the standard error from the bootstrap is quite similar to the one from b) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-webcam",
   "metadata": {},
   "source": [
    "######  (d) Based on your bootstrap estimate from (c), provide a 95 % confidence interval for the mean of medv. Compare it to the results obtained using t.test(Boston$medv)\n",
    "Hint: You can approximate a 95 % confidence interval using the formula [μˆ − 2SE(μˆ), μˆ + 2SE(μˆ)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fitting-classification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>21.7062</li><li>23.3538</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 21.7062\n",
       "\\item 23.3538\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 21.7062\n",
       "2. 23.3538\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 21.7062 23.3538"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c(22.53 - 2 * 0.4119, 22.53 + 2 * 0.4119)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accepted-saturday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tOne Sample t-test\n",
       "\n",
       "data:  Boston$medv\n",
       "t = 55.111, df = 505, p-value < 2.2e-16\n",
       "alternative hypothesis: true mean is not equal to 0\n",
       "95 percent confidence interval:\n",
       " 21.72953 23.33608\n",
       "sample estimates:\n",
       "mean of x \n",
       " 22.53281 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(Boston$medv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-closer",
   "metadata": {},
   "source": [
    "> again quite similir values for the bootstrap and t.test confidence intervals. The difference is 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-mason",
   "metadata": {},
   "source": [
    "###### (e) Based on this dataset, provide an estimate, μˆ med, for the median value of medv in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "indian-intensity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "21.2"
      ],
      "text/latex": [
       "21.2"
      ],
      "text/markdown": [
       "21.2"
      ],
      "text/plain": [
       "[1] 21.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "median(Boston$medv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-lingerie",
   "metadata": {},
   "source": [
    "###### (f) We now would like to estimate the standard error of μˆmedian. Unfortunately, there is no simple formula for computing the standard error of the median. Instead, estimate the standard error of the median using the bootstrap. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "pending-transparency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = medv, statistic = boot.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "    original  bias    std. error\n",
       "t1*     21.2 0.02295   0.3778075"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "boot.fn <- function(data, index) return(median(data[index])) \n",
    "boot(medv, boot.fn, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-medicine",
   "metadata": {},
   "source": [
    "###### (g) Based on this data set, provide an estimate for the tenth percentile of medv in Boston suburbs. Call this quantity μˆ0.1. You can use the quantile() function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "damaged-bulletin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>10%:</strong> 12.75"
      ],
      "text/latex": [
       "\\textbf{10\\textbackslash{}\\%:} 12.75"
      ],
      "text/markdown": [
       "**10%:** 12.75"
      ],
      "text/plain": [
       "  10% \n",
       "12.75 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ten.mu <- quantile(medv, c(0.1))\n",
    "ten.mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-client",
   "metadata": {},
   "source": [
    "##### (h) Use the bootstrap to estimate the standard error of μˆ ment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "impressive-greece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = medv, statistic = boot.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "    original  bias    std. error\n",
       "t1*    12.75  0.0339   0.4767526"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "boot.fn <- function(data, index) return(quantile(data[index], c(0.1))) \n",
    "boot(medv, boot.fn, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-hostel",
   "metadata": {},
   "source": [
    "> the 10% quantile is 12.75, the standard error is 0.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-coalition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
